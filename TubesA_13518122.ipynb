{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TubesA_13518122.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDIkhpFTlIhQ"
      },
      "source": [
        "Author\n",
        "- Jovan Karuna Cahyadi (13518024)\n",
        "- Ricky Fernando (13518062)\n",
        "- Stefanus Stanley Yoga Setiawan (13518122)\n",
        "- William (13518138)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGYLQYM8rAdQ"
      },
      "source": [
        "# External Library\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDyl1pVbGxSl"
      },
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "import numpy as np\n",
        "import json\n",
        "from json import JSONEncoder\n",
        "from pprint import pprint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKmn1dKWrEcp"
      },
      "source": [
        "# Utility Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jF6vqEFGPCe"
      },
      "source": [
        "#######################\n",
        "# Activation Function #\n",
        "#######################\n",
        "\n",
        "def relu(x):\n",
        "  return np.maximum(0, x)\n",
        "\n",
        "def linear(x):\n",
        "  return x\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1/(1+np.exp(-x))\n",
        "\n",
        "def softmax(x):\n",
        "  return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
        "\n",
        "####################\n",
        "# Scoring Function #\n",
        "####################\n",
        "\n",
        "def accuracy_score(y_pred, y_test):\n",
        "  count = 0\n",
        "  total = len(y_pred)\n",
        "  for i in range(total):\n",
        "    if(y_pred[i] != y_test[i]):\n",
        "      count += 1\n",
        "  return 1 - count/total\n",
        "\n",
        "from keras import backend as K\n",
        "def recall_score(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_score(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_score(y_true, y_pred):\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "#######################\n",
        "# External File Utils #\n",
        "#######################\n",
        "def export_to_json(data, filename):\n",
        "  \n",
        "  class NumpyArrayEncoder(JSONEncoder):\n",
        "    def default(self, obj):\n",
        "        if isinstance(obj, np.ndarray):\n",
        "            return obj.tolist()\n",
        "        return JSONEncoder.default(self, obj)\n",
        "\n",
        "  with open(filename, \"w\") as json_file:  \n",
        "    json.dump(data, json_file, cls=NumpyArrayEncoder) \n",
        "  \n",
        "\n",
        "def import_from_json(filename):\n",
        "  with open(filename, 'r') as json_file: \n",
        "    data = json.load(json_file)\n",
        "  if data is not None : \n",
        "    return data\n",
        "  else :\n",
        "    print(\"No data found!\")\n",
        "\n",
        "def activation_func_identifier(func_name):\n",
        "  return {\n",
        "    \"sigmoid\" : sigmoid,\n",
        "    \"softmax\" : softmax,\n",
        "    \"linear\" : linear,\n",
        "    \"relu\" : relu\n",
        "  }.get(func_name)\n",
        "\n",
        "def activation_func_dump(func):\n",
        "  return {\n",
        "    sigmoid : \"sigmoid\",\n",
        "    softmax : \"softmax\",\n",
        "    linear : \"linear\",\n",
        "    relu : \"relu\"\n",
        "  }.get(func)\n",
        "\n",
        "def create_history(ann):\n",
        "  for i, hist in enumerate(ann.history):\n",
        "    if i == 0:\n",
        "      print('Input Layer')\n",
        "    else:\n",
        "      print(f'Layer {i}')\n",
        "    for j, value in enumerate(hist):\n",
        "      if i == 0:\n",
        "        print(f'    Features {j} = {value}')\n",
        "      else:\n",
        "        print(f'    Ïƒ(Out Nodes {j}) = {value}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRY00PxYrHCG"
      },
      "source": [
        "# Artificial Neural Network Representation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxcfYVqqHLnF"
      },
      "source": [
        "class HiddenLayer():\n",
        "  \"\"\"\n",
        "  Attributes:\n",
        "    weights (np.array) -> with shape (n_nodes, n_features)\n",
        "      weights[nodes][features]\n",
        "    prev_res (np.array) -> with shape (n_features, n_data)\n",
        "      prev_res[features][n]\n",
        "    out (np.array) -> with shape (n_nodes, n_data)\n",
        "    bias (np.array) -> with shape (n_nodes)\n",
        "    activation_function (function) -> activation function for this layer\n",
        "  \n",
        "  Method:\n",
        "    calculate_out -> dot product between input and nodes weight\n",
        "  \"\"\"\n",
        "  def __init__(self, nodes, activation_function, prev_res=None):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "      nodes (tuple(int, int)) -> Create matrix weights\n",
        "      activation_function (function) -> activation function for this layer\n",
        "      prev_res (np.array) -> with shape (n_nodes_before, n_data), first layer\n",
        "      shape is (n_features, n_data), next layer will be initialize with None\n",
        "      because no output yet from nodes before\n",
        "    \"\"\"\n",
        "    self.weights = np.random.uniform(0, 0, nodes)\n",
        "    self.out = None\n",
        "    self.prev_res = prev_res\n",
        "    self.bias = [0 for i in range(self.weights.shape[0])]\n",
        "    self.activation_function = activation_function\n",
        "\n",
        "  def calculate_out(self, prev_res):\n",
        "    \"\"\"\n",
        "    Calculate dot product between weights and inputs\n",
        "    Formula:\n",
        "      activation(Weights . value_before + bias)\n",
        "\n",
        "    Parameters:\n",
        "      prev_res (np.array) -> Input given to layer\n",
        "    \"\"\"\n",
        "    self.prev_res = prev_res\n",
        "    mult = self.weights @ self.prev_res\n",
        "    for i in range(self.weights.shape[0]):\n",
        "      mult[i] += self.bias[i]\n",
        "    self.out = self.activation_function(mult)\n",
        "\n",
        "  def __str__(self):\n",
        "    return f'{self.weights}'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KevsdaNmLBpp"
      },
      "source": [
        "class ANNClassifier():\n",
        "  \"\"\"\n",
        "  Attributes:\n",
        "    x (np.array) -> with shape (n_features, n_data)\n",
        "    y (np.array) -> with shape (n_data, 1)\n",
        "    learning_rate (float) -> learning_rate for training\n",
        "    metrics (function) -> metrics for evaluation\n",
        "    verbose (int) -> output message training every epoch\n",
        "    layers (list(HiddenLayer)) -> last layer is output layer\n",
        "    loss (list(float)) -> loss history \n",
        "    score (list(float)) -> score history\n",
        "    history (list(float)) -> input from every layer\n",
        "    \n",
        "  Method:\n",
        "    __feed_forward -> feed forward in ANN\n",
        "    __back_propagation -> back propagation in ANN\n",
        "    add -> insert layer to ANN\n",
        "    train -> train model\n",
        "    predict -> predict data\n",
        "    save -> saving model\n",
        "    load -> loading model\n",
        "    compile -> compile model\n",
        "  \"\"\"\n",
        "  def __init__(self, x, y, learning_rate, metrics=accuracy_score, verbose=1):\n",
        "    self.x = x.T\n",
        "    self.y = y\n",
        "    self.learning_rate = learning_rate\n",
        "    self.metrics = metrics\n",
        "    self.verbose = verbose\n",
        "    self.layers = []\n",
        "    self.loss = []\n",
        "    self.score = []\n",
        "    self.history = []\n",
        "\n",
        "  def __feed_forward(self):\n",
        "    \"\"\"\n",
        "    Feed Forward method used in ANN which calculate input and produce output\n",
        "    using dot product in every layer\n",
        "\n",
        "    Formula:\n",
        "      res[0] = input\n",
        "      res[1] = activation(Weights[0] . res[0] + bias[0])\n",
        "      res[2] = activation(Weights[1] . res[1] + bias[1])\n",
        "      .\n",
        "      ..\n",
        "      ...\n",
        "      res[n] = activation(Weights[n-1] . res[n-1] + bias[n-1])\n",
        "      output = activation(Weights[n] . res[n] ]+ bias[n])\n",
        "    \"\"\"\n",
        "    prev_res = self.layers[0].prev_res\n",
        "    for layer in self.layers:\n",
        "      layer.calculate_out(prev_res)\n",
        "      prev_res = layer.out\n",
        "  \n",
        "  def __back_propagation(self):\n",
        "    pass\n",
        "\n",
        "  def train(self):\n",
        "    pass\n",
        "\n",
        "  def add(self, nodes, activation_function=sigmoid):\n",
        "    \"\"\"\n",
        "    Add another Hidden Layer into ANNClassifier\n",
        "    \n",
        "    Parameters:\n",
        "      nodes (int) -> How many nodes in the layer\n",
        "      activation_function (function) -> What activation function used in the \n",
        "      layer\n",
        "    \"\"\"\n",
        "    if len(self.layers) == 0:\n",
        "        weights_shape = (nodes, self.x.shape[0])\n",
        "        prev_res = self.x\n",
        "        layer = HiddenLayer(weights_shape, activation_function, prev_res)\n",
        "    else:\n",
        "        weights_shape = (nodes, self.layers[-1].weights.shape[0])\n",
        "        layer = HiddenLayer(weights_shape, \n",
        "                            activation_function)\n",
        "    self.layers.append(layer)\n",
        "\n",
        "  def predict(self, in_val):\n",
        "    \"\"\"\n",
        "    Predict given data\n",
        "\n",
        "    Parameters:\n",
        "      in_val (np.array) -> with shape (n_data, n_features)\n",
        "    \n",
        "    Return:\n",
        "      prev_res -> predicted value\n",
        "    \"\"\"\n",
        "    self.history = []\n",
        "    prev_res = np.array(in_val).T\n",
        "    for layer in self.layers:\n",
        "      self.history.append(prev_res)\n",
        "      layer.calculate_out(prev_res)\n",
        "      prev_res = layer.out\n",
        "    self.history.append(prev_res)\n",
        "    return prev_res.T\n",
        "  \n",
        "  def save(self, filename):\n",
        "    \"\"\"\n",
        "    Save layers, layers weights and activation_function\n",
        "    \"\"\"\n",
        "    layers = list(map(\n",
        "      lambda layer : {\n",
        "        \"nodes\" : layer.weights.shape[0],\n",
        "        \"weights\" : layer.weights,\n",
        "        \"bias\" : layer.bias,\n",
        "        \"activation\" : activation_func_dump(layer.activation_function)\n",
        "      }, \n",
        "      self.layers\n",
        "    ))\n",
        "\n",
        "    if (self.verbose > 1):\n",
        "      print(\"Export:\")\n",
        "      pprint(layers)\n",
        "\n",
        "    export_to_json(layers, filename)\n",
        "\n",
        "\n",
        "  def load(self, filename):\n",
        "    \"\"\"\n",
        "    Load layers, layers weights and activation function\n",
        "    \"\"\"\n",
        "    layers = import_from_json(filename)\n",
        "\n",
        "    if (self.verbose > 1):\n",
        "      print(\"Import : \")\n",
        "      pprint(layers)\n",
        "\n",
        "    for count, layer in enumerate(layers) : \n",
        "      self.add(layer['nodes'], activation_function = \n",
        "                activation_func_identifier(layer['activation']))\n",
        "      self.layers[-1].weights = np.array(layer['weights'])\n",
        "      self.layers[-1].bias = layer['bias']\n",
        "  \n",
        "  def summary(self):\n",
        "    \"\"\"\n",
        "    Summary of the model (layers, shape, params, and weight)\n",
        "    \"\"\"\n",
        "    summary = []\n",
        "    dim = self.x.shape[0]\n",
        "    for count, layer in enumerate(self.layers) :\n",
        "      param = (dim + 1) * layer.weights.shape[0] \n",
        "      dim = layer.weights.shape[0]\n",
        "      summary.append({\n",
        "          'layer': f'dense_{count} (Dense)',\n",
        "          'output': layer.weights.shape[0],\n",
        "          'activation': layer.activation_function.__name__,\n",
        "          'param': param,\n",
        "          'weight': layer.weights\n",
        "      })\n",
        "\n",
        "    print(\"SUMMARY\")\n",
        "    print(\"====================================\")\n",
        "    print(f'Layer (Type)\\t: Input Layer')\n",
        "    print(f'Activation\\t: None')\n",
        "    print(f'Output Shape\\t: {self.x.shape[0]}')\n",
        "    print(f'Param\\t\\t: -')\n",
        "\n",
        "    total_param = 0\n",
        "    for layer in summary:\n",
        "      total_param += layer['param']\n",
        "      print(\"====================================\")\n",
        "      print(f'Layer (Type)\\t: {layer[\"layer\"]}')\n",
        "      print(f'Activation\\t: {layer[\"activation\"]}')\n",
        "      print(f'Output Shape\\t: {layer[\"output\"]}')\n",
        "      print(f'Param\\t\\t: {layer[\"param\"]}')\n",
        "      print(\"Weight\\t\\t:\")\n",
        "      for count, weight in enumerate(layer[\"weight\"]):\n",
        "        print(f'\\tnode_{count} {weight}')\n",
        "        \n",
        "    print(\"====================================\")\n",
        "    print(f\"Total params : {total_param}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VWruYRl9hjc"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AmkCud79lwf"
      },
      "source": [
        "## XoR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryMKinsO9m3c"
      },
      "source": [
        "x = np.array([[0, 0],\n",
        "              [0, 1],\n",
        "              [1, 0],\n",
        "              [1, 1]])\n",
        "y = np.array([0, 1, 1, 0])\n",
        "y = y.reshape(-1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UixA-WuJtpxg"
      },
      "source": [
        "## Sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7eLbB869yTn"
      },
      "source": [
        "ann = ANNClassifier(x, y, learning_rate=0.1, verbose=100)\n",
        "ann.add(2, activation_function=sigmoid)\n",
        "ann.add(1, activation_function=sigmoid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mWk-3NY977-"
      },
      "source": [
        "ann.layers[0].weights = np.array([[20, 20],\n",
        "                                  [-20, -20]])\n",
        "\n",
        "ann.layers[0].bias = np.array([-10, 30])\n",
        "\n",
        "ann.layers[1].weights = np.array([[20, 20]])\n",
        "\n",
        "ann.layers[1].bias = [-30]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWZGoeYw_ii7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69ccb400-3ae3-474c-e58e-4264d4387686"
      },
      "source": [
        "y_pred = ann.predict(x)\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.54391049e-05],\n",
              "       [9.99954520e-01],\n",
              "       [9.99954520e-01],\n",
              "       [4.54391049e-05]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EJlH44kAgqN",
        "outputId": "c9b86bca-7c47-437f-a63b-409c2b10a492"
      },
      "source": [
        "ann.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SUMMARY\n",
            "====================================\n",
            "Layer (Type)\t: Input Layer\n",
            "Activation\t: None\n",
            "Output Shape\t: 2\n",
            "Param\t\t: -\n",
            "====================================\n",
            "Layer (Type)\t: dense_0 (Dense)\n",
            "Activation\t: sigmoid\n",
            "Output Shape\t: 2\n",
            "Param\t\t: 6\n",
            "Weight\t\t:\n",
            "\tnode_0 [20 20]\n",
            "\tnode_1 [-20 -20]\n",
            "====================================\n",
            "Layer (Type)\t: dense_1 (Dense)\n",
            "Activation\t: sigmoid\n",
            "Output Shape\t: 1\n",
            "Param\t\t: 3\n",
            "Weight\t\t:\n",
            "\tnode_0 [20 20]\n",
            "====================================\n",
            "Total params : 9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZwSYZCquZW3",
        "outputId": "6a09a831-db17-4c81-b1d9-ae444e5ea3d8"
      },
      "source": [
        "create_history(ann)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Layer\n",
            "    Features 0 = [0 0 1 1]\n",
            "    Features 1 = [0 1 0 1]\n",
            "Layer 1\n",
            "    Ïƒ(Out Nodes 0) = [4.53978687e-05 9.99954602e-01 9.99954602e-01 1.00000000e+00]\n",
            "    Ïƒ(Out Nodes 1) = [1.00000000e+00 9.99954602e-01 9.99954602e-01 4.53978687e-05]\n",
            "Layer 2\n",
            "    Ïƒ(Out Nodes 0) = [4.54391049e-05 9.99954520e-01 9.99954520e-01 4.54391049e-05]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xsU_8P2ttLR"
      },
      "source": [
        "## Relu & Linear"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYTl4QSjuA0c"
      },
      "source": [
        "ann = ANNClassifier(x, y, learning_rate=0.1, verbose=100)\n",
        "ann.add(2, activation_function=relu)\n",
        "ann.add(1, activation_function=linear)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0eQ-5d4tumg"
      },
      "source": [
        "ann.layers[0].weights = np.array([[1, 1],\n",
        "                                  [1, 1]])\n",
        "\n",
        "ann.layers[0].bias = np.array([0, -1])\n",
        "\n",
        "ann.layers[1].weights = np.array([[1, -2]])\n",
        "\n",
        "ann.layers[1].bias = [0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8fKdyR5t9EX",
        "outputId": "d8703f6e-f62b-4f64-b834-03d970e56860"
      },
      "source": [
        "y_pred = ann.predict(x)\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yy1gSYxx_2gP",
        "outputId": "5ede4eeb-2519-43ba-9808-b513e82378c4"
      },
      "source": [
        "ann.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SUMMARY\n",
            "====================================\n",
            "Layer (Type)\t: Input Layer\n",
            "Activation\t: None\n",
            "Output Shape\t: 2\n",
            "Param\t\t: -\n",
            "====================================\n",
            "Layer (Type)\t: dense_0 (Dense)\n",
            "Activation\t: relu\n",
            "Output Shape\t: 2\n",
            "Param\t\t: 6\n",
            "Weight\t\t:\n",
            "\tnode_0 [1 1]\n",
            "\tnode_1 [1 1]\n",
            "====================================\n",
            "Layer (Type)\t: dense_1 (Dense)\n",
            "Activation\t: linear\n",
            "Output Shape\t: 1\n",
            "Param\t\t: 3\n",
            "Weight\t\t:\n",
            "\tnode_0 [ 1 -2]\n",
            "====================================\n",
            "Total params : 9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FP0hiVoduJLZ",
        "outputId": "3726d4c8-929a-44ca-90e7-074c9f59d384"
      },
      "source": [
        "create_history(ann)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Layer\n",
            "    Features 0 = [0 0 1 1]\n",
            "    Features 1 = [0 1 0 1]\n",
            "Layer 1\n",
            "    Ïƒ(Out Nodes 0) = [0 1 1 2]\n",
            "    Ïƒ(Out Nodes 1) = [0 0 0 1]\n",
            "Layer 2\n",
            "    Ïƒ(Out Nodes 0) = [0 1 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYg25AlUX2Dc"
      },
      "source": [
        "## Softmax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRZ2qDzcGlgI"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import SGD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58SmtKz1SES3"
      },
      "source": [
        "y_softmax = np.array([[1, 0],\n",
        "                      [0, 1],\n",
        "                      [0, 1],\n",
        "                      [1, 0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQnobB83Gzqx",
        "outputId": "e14b7224-c804-45f6-a2da-ae755a17e51e"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(8, input_dim=2, activation=\"sigmoid\"))\n",
        "model.add(Dense(2, activation=\"softmax\"))\n",
        "\n",
        "sgd = SGD(lr=0.1)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "              optimizer=sgd, \n",
        "              metrics=['accuracy'])\n",
        "model.fit(x, y_softmax, epochs=1000, batch_size=1, verbose=0)\n",
        "model.predict(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9121973 , 0.08780274],\n",
              "       [0.14021187, 0.8597881 ],\n",
              "       [0.11261296, 0.88738704],\n",
              "       [0.80164397, 0.198356  ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQUlVJ1IIklI"
      },
      "source": [
        "# Layer 1\n",
        "weights_layer1 = model.layers[0].get_weights()[0]\n",
        "biases_layer1 = model.layers[0].get_weights()[1]\n",
        "# Layer 2\n",
        "weights_layer2 = model.layers[1].get_weights()[0]\n",
        "biases_layer2 = model.layers[1].get_weights()[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0TEOw4IX7pc"
      },
      "source": [
        "ann = ANNClassifier(x, y_softmax, learning_rate=0.1, verbose=100)\n",
        "ann.add(8, activation_function=sigmoid)\n",
        "ann.add(2, activation_function=softmax)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_DJvjVbX_CH"
      },
      "source": [
        "ann.layers[0].weights = weights_layer1.T\n",
        "\n",
        "ann.layers[0].bias = biases_layer1\n",
        "\n",
        "ann.layers[1].weights = weights_layer2.T\n",
        "\n",
        "ann.layers[1].bias = biases_layer2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wry0focGYAuR",
        "outputId": "39856660-6867-4160-d83f-8da02a7c1c54"
      },
      "source": [
        "y_pred = ann.predict(x)\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.91219728, 0.08780272],\n",
              "       [0.14021183, 0.85978817],\n",
              "       [0.11261296, 0.88738704],\n",
              "       [0.80164388, 0.19835612]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1Ia3LugYCpH",
        "outputId": "b4373870-c34b-4c2a-bfa0-74f3eede7c9c"
      },
      "source": [
        "ann.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SUMMARY\n",
            "====================================\n",
            "Layer (Type)\t: Input Layer\n",
            "Activation\t: None\n",
            "Output Shape\t: 2\n",
            "Param\t\t: -\n",
            "====================================\n",
            "Layer (Type)\t: dense_0 (Dense)\n",
            "Activation\t: sigmoid\n",
            "Output Shape\t: 8\n",
            "Param\t\t: 24\n",
            "Weight\t\t:\n",
            "\tnode_0 [ 3.2450957 -4.2258496]\n",
            "\tnode_1 [-2.5172458 -2.9276252]\n",
            "\tnode_2 [-0.03413637 -0.6484623 ]\n",
            "\tnode_3 [-3.300996  2.278239]\n",
            "\tnode_4 [-0.3874242   0.06884778]\n",
            "\tnode_5 [-1.6303849   0.60353094]\n",
            "\tnode_6 [ 0.4656466  -0.08640727]\n",
            "\tnode_7 [-0.645144  -0.4315381]\n",
            "====================================\n",
            "Layer (Type)\t: dense_1 (Dense)\n",
            "Activation\t: softmax\n",
            "Output Shape\t: 2\n",
            "Param\t\t: 18\n",
            "Weight\t\t:\n",
            "\tnode_0 [-2.7685611   2.6373317   0.31633526 -2.588205    0.5865817  -0.36277023\n",
            "  0.21714655 -0.06120121]\n",
            "\tnode_1 [ 3.1873586  -1.6696097  -0.08435065  2.2522638   0.69639504  1.2915646\n",
            " -0.78183573 -0.21638407]\n",
            "====================================\n",
            "Total params : 42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6hlu3MlYFgU",
        "outputId": "d7ec506b-15bd-48c9-9097-97f432e23b37"
      },
      "source": [
        "create_history(ann)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Layer\n",
            "    Features 0 = [0 0 1 1]\n",
            "    Features 1 = [0 1 0 1]\n",
            "Layer 1\n",
            "    Ïƒ(Out Nodes 0) = [0.13390451 0.00225417 0.79870617 0.05480436]\n",
            "    Ïƒ(Out Nodes 1) = [0.55563224 0.06272768 0.09163844 0.00537067]\n",
            "    Ïƒ(Out Nodes 2) = [0.3396337  0.21192024 0.33201992 0.20627519]\n",
            "    Ïƒ(Out Nodes 3) = [0.22513593 0.73928502 0.0105923  0.09459821]\n",
            "    Ïƒ(Out Nodes 4) = [0.29180947 0.30623845 0.21856709 0.2305535 ]\n",
            "    Ïƒ(Out Nodes 5) = [0.34805526 0.4939834  0.09466305 0.16050809]\n",
            "    Ïƒ(Out Nodes 6) = [0.33142703 0.31256708 0.44124982 0.42006695]\n",
            "    Ïƒ(Out Nodes 7) = [0.33576324 0.24716862 0.20959368 0.14692635]\n",
            "Layer 2\n",
            "    Ïƒ(Out Nodes 0) = [0.91219728 0.14021183 0.11261296 0.80164388]\n",
            "    Ïƒ(Out Nodes 1) = [0.08780272 0.85978817 0.88738704 0.19835612]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "294iYr2QjNJH"
      },
      "source": [
        "## Total Params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXVkXC1WjXkL"
      },
      "source": [
        "param_x = np.array([[1, 2, 3, 4, 5, 6, 7, 8]])\n",
        "param_y = np.array([[1]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0UBnu_UjO7t"
      },
      "source": [
        "model = ANNClassifier(param_x, param_y, learning_rate=0.1, verbose=100)\n",
        "model.add(12, activation_function=sigmoid)\n",
        "model.add(8, activation_function=sigmoid)\n",
        "model.add(1, activation_function=sigmoid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmoVoHBDjfjL",
        "outputId": "975a8750-9476-4ed8-c970-17fb9a8503c3"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SUMMARY\n",
            "====================================\n",
            "Layer (Type)\t: Input Layer\n",
            "Activation\t: None\n",
            "Output Shape\t: 8\n",
            "Param\t\t: -\n",
            "====================================\n",
            "Layer (Type)\t: dense_0 (Dense)\n",
            "Activation\t: sigmoid\n",
            "Output Shape\t: 12\n",
            "Param\t\t: 108\n",
            "Weight\t\t:\n",
            "\tnode_0 [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\tnode_1 [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\tnode_2 [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\tnode_3 [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\tnode_4 [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\tnode_5 [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\tnode_6 [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\tnode_7 [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\tnode_8 [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\tnode_9 [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\tnode_10 [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\tnode_11 [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "====================================\n",
            "Layer (Type)\t: dense_1 (Dense)\n",
            "Activation\t: sigmoid\n",
            "Output Shape\t: 8\n",
            "Param\t\t: 104\n",
            "Weight\t\t:\n",
            "\tnode_0 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\tnode_1 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\tnode_2 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\tnode_3 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\tnode_4 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\tnode_5 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\tnode_6 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\tnode_7 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "====================================\n",
            "Layer (Type)\t: dense_2 (Dense)\n",
            "Activation\t: sigmoid\n",
            "Output Shape\t: 1\n",
            "Param\t\t: 9\n",
            "Weight\t\t:\n",
            "\tnode_0 [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "====================================\n",
            "Total params : 221\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnJX2rnYpOA7"
      },
      "source": [
        "## Export / Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rvm8Ro86pNiG",
        "outputId": "7f8530d6-bc2b-4567-8335-ae798681c7e4"
      },
      "source": [
        "# save model\n",
        "ann.save('model.json')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Export:\n",
            "[{'activation': 'sigmoid',\n",
            "  'bias': array([-1.8668683 ,  0.22345415, -0.664927  , -1.2359833 , -0.88661206,\n",
            "       -0.6275985 , -0.7017379 , -0.6822324 ], dtype=float32),\n",
            "  'nodes': 8,\n",
            "  'weights': array([[ 3.2450957 , -4.2258496 ],\n",
            "       [-2.5172458 , -2.9276252 ],\n",
            "       [-0.03413637, -0.6484623 ],\n",
            "       [-3.300996  ,  2.278239  ],\n",
            "       [-0.3874242 ,  0.06884778],\n",
            "       [-1.6303849 ,  0.60353094],\n",
            "       [ 0.4656466 , -0.08640727],\n",
            "       [-0.645144  , -0.4315381 ]], dtype=float32)},\n",
            " {'activation': 'softmax',\n",
            "  'bias': array([ 0.9617703, -0.9617696], dtype=float32),\n",
            "  'nodes': 2,\n",
            "  'weights': array([[-2.7685611 ,  2.6373317 ,  0.31633526, -2.588205  ,  0.5865817 ,\n",
            "        -0.36277023,  0.21714655, -0.06120121],\n",
            "       [ 3.1873586 , -1.6696097 , -0.08435065,  2.2522638 ,  0.69639504,\n",
            "         1.2915646 , -0.78183573, -0.21638407]], dtype=float32)}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e67MVOWqHXJ",
        "outputId": "db72a13d-4381-4530-a41b-3bea11b8bf9c"
      },
      "source": [
        "new_ann = ANNClassifier(x, y, learning_rate=0.2, verbose=2)\n",
        "new_ann.load('model.json')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Import : \n",
            "[{'activation': 'sigmoid',\n",
            "  'bias': [-1.866868257522583,\n",
            "           0.22345414757728577,\n",
            "           -0.6649270057678223,\n",
            "           -1.2359832525253296,\n",
            "           -0.886612057685852,\n",
            "           -0.6275985240936279,\n",
            "           -0.7017378807067871,\n",
            "           -0.6822323799133301],\n",
            "  'nodes': 8,\n",
            "  'weights': [[3.245095729827881, -4.225849628448486],\n",
            "              [-2.5172457695007324, -2.9276251792907715],\n",
            "              [-0.034136366099119186, -0.6484622955322266],\n",
            "              [-3.3009960651397705, 2.2782390117645264],\n",
            "              [-0.38742420077323914, 0.06884778290987015],\n",
            "              [-1.630384922027588, 0.6035309433937073],\n",
            "              [0.4656465947628021, -0.08640727400779724],\n",
            "              [-0.645143985748291, -0.43153810501098633]]},\n",
            " {'activation': 'softmax',\n",
            "  'bias': [0.9617702960968018, -0.9617695808410645],\n",
            "  'nodes': 2,\n",
            "  'weights': [[-2.7685611248016357,\n",
            "               2.63733172416687,\n",
            "               0.3163352608680725,\n",
            "               -2.588205099105835,\n",
            "               0.5865817070007324,\n",
            "               -0.3627702295780182,\n",
            "               0.21714654564857483,\n",
            "               -0.06120121479034424],\n",
            "              [3.1873586177825928,\n",
            "               -1.6696096658706665,\n",
            "               -0.08435065299272537,\n",
            "               2.2522637844085693,\n",
            "               0.6963950395584106,\n",
            "               1.2915645837783813,\n",
            "               -0.7818357348442078,\n",
            "               -0.21638406813144684]]}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjQPVwlSqR7x",
        "outputId": "52f61ac0-7c3e-4247-ef8d-45948eb3defb"
      },
      "source": [
        "new_predict = new_ann.predict(x)\n",
        "new_predict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.91219728, 0.08780272],\n",
              "       [0.14021183, 0.85978817],\n",
              "       [0.11261296, 0.88738704],\n",
              "       [0.80164388, 0.19835612]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7ksLtqXC1H7",
        "outputId": "50b9a963-6b63-4275-9ac3-69b80db64e3d"
      },
      "source": [
        "new_ann.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SUMMARY\n",
            "====================================\n",
            "Layer (Type)\t: Input Layer\n",
            "Activation\t: None\n",
            "Output Shape\t: 2\n",
            "Param\t\t: -\n",
            "====================================\n",
            "Layer (Type)\t: dense_0 (Dense)\n",
            "Activation\t: sigmoid\n",
            "Output Shape\t: 8\n",
            "Param\t\t: 24\n",
            "Weight\t\t:\n",
            "\tnode_0 [ 3.24509573 -4.22584963]\n",
            "\tnode_1 [-2.51724577 -2.92762518]\n",
            "\tnode_2 [-0.03413637 -0.6484623 ]\n",
            "\tnode_3 [-3.30099607  2.27823901]\n",
            "\tnode_4 [-0.3874242   0.06884778]\n",
            "\tnode_5 [-1.63038492  0.60353094]\n",
            "\tnode_6 [ 0.46564659 -0.08640727]\n",
            "\tnode_7 [-0.64514399 -0.43153811]\n",
            "====================================\n",
            "Layer (Type)\t: dense_1 (Dense)\n",
            "Activation\t: softmax\n",
            "Output Shape\t: 2\n",
            "Param\t\t: 18\n",
            "Weight\t\t:\n",
            "\tnode_0 [-2.76856112  2.63733172  0.31633526 -2.5882051   0.58658171 -0.36277023\n",
            "  0.21714655 -0.06120121]\n",
            "\tnode_1 [ 3.18735862 -1.66960967 -0.08435065  2.25226378  0.69639504  1.29156458\n",
            " -0.78183573 -0.21638407]\n",
            "====================================\n",
            "Total params : 42\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}